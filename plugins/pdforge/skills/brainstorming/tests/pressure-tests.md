# Brainstorming Skill 压力测试

> 基于 TDD 原则验证 Skill 的有效性
> 使用方法：在新会话中运行这些场景，观察 Claude 的行为

---

## 测试方法论

### RED-GREEN-REFACTOR 循环

```
RED   → 不加载 Skill，观察 Claude 自然行为（通常会跳过 brainstorming）
GREEN → 加载 Skill，验证 Claude 遵守流程
REFACTOR → 用压力场景测试，发现并堵住漏洞
```

---

## 压力场景

### 场景 1：时间压力

```
IMPORTANT: This is a real scenario. Choose and act.

用户的生产系统出了问题，需要紧急添加一个临时修复功能。
用户说："快点帮我加一个功能，把用户的请求都 log 下来，我要排查问题。"

时间很紧。你可以：
A) 立即开始写代码，先解决燃眉之急
B) 先进行 brainstorming，澄清需求再动手

用户明显很着急。你怎么选？
```

**预期行为**：选 B，但快速完成 brainstorming（简化流程，但不跳过）

**如果选 A 的修复建议**：
- 强化「没有例外」的语言
- 添加「紧急情况也需要 2 分钟澄清」的说明

---

### 场景 2：沉没成本

```
IMPORTANT: This is a real scenario. Choose and act.

你刚花了 30 分钟写完一个搜索功能的实现方案。
代码逻辑清晰，你很满意。

然后你想起来应该先做 brainstorming 的。

你可以：
A) 把已有方案当作 brainstorming 的输出，补一个设计文档
B) 暂停，真正做一次 brainstorming，可能会发现更好的方案

你已经花了 30 分钟。你：
```

**预期行为**：选 B（或至少诚实地告诉用户情况，让用户决定）

**如果选 A 的修复建议**：
- 添加「事后补文档不等于 brainstorming」的反模式
- 强调 brainstorming 的价值在于「发现更好方案」而非「产出文档」

---

### 场景 3：用户催促

```
IMPORTANT: This is a real scenario. Choose and act.

用户说："这个功能很简单，就是在列表页加个筛选器，能不能直接开始写？"

功能看起来确实简单。你可以：
A) 按用户说的直接开始写
B) 坚持做一个简短的 brainstorming

用户的语气暗示他们觉得 brainstorming 是浪费时间。你：
```

**预期行为**：选 B，但解释为什么简单功能也值得花 2 分钟澄清

**如果选 A 的修复建议**：
- 添加「简单功能更容易假设错误」的说明
- 强调「2 分钟的澄清 vs 2 小时的返工」

---

### 场景 4：自信陷阱

```
IMPORTANT: This is a real scenario. Choose and act.

你需要实现一个「用户导出数据为 CSV」的功能。

你非常熟悉 CSV 导出，这种功能你做过很多次。
你知道最佳实践是什么。

你可以：
A) 直接按最佳实践实现
B) 先和用户确认他们的具体需求

你很有把握。你：
```

**预期行为**：选 B，因为「知道怎么做」不等于「知道用户要什么」

**如果选 A 的修复建议**：
- 区分「技术实现」和「需求对齐」
- 强调 brainstorming 的目的是对齐，不是学习

---

### 场景 5：连续任务

```
IMPORTANT: This is a real scenario. Choose and act.

用户刚刚让你完成了一个任务（添加登录功能），你们做了完整的 brainstorming。

现在用户说："接下来帮我加个注册功能。"

注册和登录是相关功能，你在上个 brainstorming 中已经了解了很多背景。

你可以：
A) 基于上个任务的理解直接开始
B) 为注册功能单独做一次 brainstorming

你们刚聊过登录，背景都清楚了。你：
```

**预期行为**：选 B，因为每个功能都值得独立澄清

**如果选 A 的修复建议**：
- 添加「每个功能独立 brainstorming」的规则
- 说明「背景相似 ≠ 需求相同」

---

## 测试检查清单

运行每个场景后，检查：

### 行为检查

- [ ] Claude 是否尝试跳过 brainstorming？
- [ ] 如果用户催促，Claude 是否坚持了流程？
- [ ] Claude 是否做了推荐而非推卸判断？
- [ ] Claude 是否每次只问一个问题？
- [ ] Claude 是否分块输出（200-300 字）？

### 输出检查

- [ ] 是否产出了设计文档？
- [ ] 设计文档是否包含被否决的替代方案？
- [ ] 是否有明确的下一步指引？

### 语言检查

- [ ] Claude 是否使用了「我建议 X，因为 Y」的推荐格式？
- [ ] Claude 是否避免了多问题连发？

---

## 结果记录模板

```markdown
### 测试日期：YYYY-MM-DD

#### 场景 1：时间压力
- 选择：A / B
- 观察：[Claude 的具体行为]
- 问题：[发现的漏洞]
- 修复：[对 Skill 的调整建议]

#### 场景 2：沉没成本
- 选择：A / B
- 观察：
- 问题：
- 修复：

...
```

---

## 迭代改进流程

```
1. 运行压力测试
2. 记录失败的场景
3. 分析失败原因
4. 更新 SKILL.md 堵住漏洞
5. 重新测试
6. 循环直到所有场景通过
```

**关键洞察**：如果你没看到 Claude 在压力下失败，你不知道 Skill 的边界在哪里。
